df["ACL",y] <-  NA
df["1-SPR",y] <-  1- basemod10$derived_quants[grep(paste0("SPRratio_",YOI[y],collapse = "|"), basemod10$derived_quants$Label),"Value"]
df["ExploitationRate",y] <-  basemod10$derived_quants[grep(paste0("F_",YOI[y],collapse = "|"), basemod10$derived_quants$Label),"Value"]
df["A10+Biomass",y] <- subset(basemod10$timeseries[, c('Yr', 'Bio_smry')], Yr == YOI[y])$Bio_smry
df["SpawnBiomass",y] <-  basemod10$derived_quants[grep(paste0("SSB_",YOI[y],collapse = "|"), basemod10$derived_quants$Label),"Value"]
df["Spawnbio95CI",y] <-  paste0( round( as.numeric(df["SpawnBiomass",y])-1.96*basemod10$derived_quants[grep(paste0("SSB_",YOI[y],collapse = "|"), basemod10$derived_quants$Label),"StdDev"]),"--",
round(as.numeric(df["SpawnBiomass",y])+1.96*basemod10$derived_quants[grep(paste0("SSB_",YOI[y],collapse = "|"), basemod10$derived_quants$Label),"StdDev"]))
df["Rec",y] <- round(basemod10$derived_quants[grep(paste0("Recr_",YOI[y],collapse = "|"), basemod10$derived_quants$Label),"Value"],2)
df["Rec95CI",y] <- paste0( round(as.numeric(df["Rec",y])  - 1.96*basemod10$derived_quants[grep(paste0("Recr_",YOI[y],collapse = "|"), basemod10$derived_quants$Label),"StdDev"],2),"--",
round(as.numeric(df["Rec",y]) + 1.96*basemod10$derived_quants[grep(paste0("Recr_",YOI[y],collapse = "|"), basemod10$derived_quants$Label),"StdDev"],2))
# dq - qnorm(1-(1-quant)/2)*sd chantel this is 1.96
df["Depletion",y] <- paste0(round(basemod10$derived_quants[grep(paste0("Bratio_",YOI[y],collapse = "|"), basemod10$derived_quants$Label),"Value"],3)*100,"%")
df["Depl95CI",y] <- paste0( round(as.numeric(df["Rec",y])  - 1.96*basemod10$derived_quants[grep(paste0("Bratio_",YOI[y],collapse = "|"), basemod10$derived_quants$Label),"StdDev"],2),"--",
round(as.numeric(df["Rec",y] )+ 1.96*basemod10$derived_quants[grep(paste0("Bratio_",YOI[y],collapse = "|"), basemod10$derived_quants$Label),"StdDev"],2))
}
colnames(df)<- YOI
write.csv(df,paste0(rootdir.temp,"./",Sys.Date(),r,"table_i.csv"), row.names = TRUE)
## Figure E TS of Harvest rate: points with SE, red line with SPR50%
SSplotSummaryF(basemod10,  print = T, Ftgt = basemod10$derived_quants[grep("Fstd_SPRtgt", basemod10$derived_quants$Label),"Value"], plotdir = rootdir.temp)
SSplotCatch(basemod10, subplot = 2,  print = T, plotdir = rootdir.temp)
SSplotTimeseries(basemod10, subplot = 11, print = T, plotdir = rootdir.temp, forecastplot = FALSE)
SSplotTimeseries(basemod10, subplot = 9,  print = T, plotdir = rootdir.temp, forecastplot = FALSE)
SSplotSPR(basemod10,subplot = 4, print = TRUE, plotdir = rootdir.temp, forecastplot = FALSE)
SSplotSPR(basemod10,subplot = 2, print = T, plotdir = rootdir.temp, forecastplot = FALSE)
SSB_sd.Yr <- basemod10$derived_quants[grep("SSB_", basemod10$derived_quants$Label),"StdDev"][1:134]
basemod10$timeseries %>%
select(Yr, SpawnBio) %>%
mutate(upper = SpawnBio + 1.96*SSB_sd.Yr, lwr = SpawnBio - 1.96*SSB_sd.Yr) %>%
ggplot(., aes(x= Yr, y = SpawnBio)) +
theme_classic()+
geom_line(lwd =1.1) +
# scale_x_continuous(limits = c(1900, 2019), breaks = seq(1900,2020,20)) +
# scale_y_continuous(limits = c(0,), breaks = seq(0,90,15)) +
geom_ribbon(aes(ymin = lwr, ymax = upper), alpha = 0.2) +
labs(x = 'Year', y = 'Spawning Biomass (000 mt)', title = r)
ggsave(last_plot(), file = paste0(rootdir.temp,"/",r,"_SSBtimeseries.png"), height = 4, width = 6, units = 'in', dpi = 420)
# data.frame("SPR" = basemod10$derived_quants[grep("SPRratio_", basemod10$derived_quants$Label),"Value"],
#              "sd" = basemod10$derived_quants[grep("SPRratio_", basemod10$derived_quants$Label),"StdDev"],
#              "Yr" = as.numeric(as.character(substr(basemod10$derived_quants[grep("SPRratio_", basemod10$derived_quants$Label),"Label"],10,14)))) %>%
#   filter(Yr < 2021) %>%
#   mutate(lwr = SPR-1.96*sd, upper = SPR+1.96*sd ) %>%
#   ggplot(., aes(x= Yr, y = 1-SPR)) +
#   theme_classic()+
#   geom_point()+
#   geom_hline(yintercept = basemod10$derived_quants[grep("Fstd_SPRtgt", basemod10$derived_quants$Label),"Value"], col = 'red')+
#   # scale_x_continuous(limits = c(1900, 2019), breaks = seq(1900,2020,20)) +
#   scale_y_continuous(limits = c(0,1)) +
#   geom_errorbar(aes(ymin = 1-lwr, ymax = 1-upper), col = 'grey22' ) +
#   labs(x = 'Year', y = '1-SPR', title = r)
# ggsave(last_plot(), file = paste0(rootdir.temp,"/",r,"_1-SPR.png"), height = 4, width = 6, units = 'in', dpi = 420)
}
regnames
# regnames <- basename(regdirs)
regnames <- basename(dirname(list.files(regdirs, recursive = FALSE, full.names = TRUE)[grep(paste0(Sys.Date(),'table_i.csv'),list.files(regdirs,recursive = FALSE,full.names = TRUE))]))
regdirs <- list.dirs(rootdir,recursive = FALSE)[grep('cr',list.dirs(rootdir,recursive = FALSE))]
# regnames <- basename(regdirs)
regnames <- basename(dirname(list.files(regdirs, recursive = FALSE, full.names = TRUE)[grep(paste0(Sys.Date(),'table_i.csv'),list.files(regdirs,recursive = FALSE,full.names = TRUE))]))
regnames
# regnames <- basename(regdirs)
regnames <- basename(dirname(list.files(regdirs, recursive = FALSE, full.names = TRUE)[grep('table_i.csv',list.files(regdirs,recursive = FALSE,full.names = TRUE))]))
regnames
regnames <- basename(regdirs)
basename(regdirs)
regnames
# regnames <- basename(regdirs)
regnames <- basename(dirname(list.files(regdirs, recursive = FALSE, full.names = TRUE)[grep('table_i.csv',list.files(regdirs,recursive = FALSE,full.names = TRUE))]))
regnames
list.files(regdirs, recursive = FALSE, full.names = TRUE)[grep(paste0('table_i.csv'),list.files(regdirs,recursive = FALSE,full.names = TRUE))]
basename(regnames)
apply(basename(regnames), rep(20))
list.files(regdirs, recursive = FALSE, full.names = TRUE)[grep(paste0('table_i.csv'),list.files(regdirs,recursive = FALSE,full.names = TRUE))] %>%
lapply(.,read.csv)
df <- list.files(regdirs, recursive = FALSE, full.names = TRUE)[grep(paste0('table_i.csv'),list.files(regdirs,recursive = FALSE,full.names = TRUE))] %>%
lapply(.,read.csv) %>%
bind_rows()
for(i in 1:length(basename(regnames))){
df$REG[(1:13)*i] <- basename(regnames)[i]
}
head(df)
sub("cr","",basename(regnames)[i])
for(i in 1:length(basename(regnames))){
df$REG[(1:13)*i] <- sub("cr","",basename(regnames)[i])
}
write.csv(df,paste0(rootdir,"/",Sys.Date(),"summary_table_i.csv"), row.names = TRUE)
(1:13)+c(0,13,26)[i]
i
for(i in 1:length(basename(regnames))){
idx <- (1:13)+c(0,13,26)[i]
df$REG[idx] <- sub("cr","",basename(regnames)[i])
}
write.csv(df,paste0(rootdir,"/",Sys.Date(),"summary_table_i.csv"), row.names = TRUE)
exp(-2.94)
exp(-2.99)
exp(-2.41)
log(0.07)
install.packages("phaseR")
?phaseR
install.packages("phaseR")
require(phaseR)
r = 'North'
catch = 'ABC'
state = 'low'
if(catch == 'ABC' & state == 'base'){
rootdir.temp <- paste0(rootdir,"/cr",r )
lastrun <- paste0(rootdir.temp,"/forecasts/forecast2030")
newdir.temp <- paste0(rootdir,"/cr",r,"_",catch,"_",state)
dir.create(newdir.temp) ## make special folder and copy files
file.copy(list.files(lastrun,
full.names = TRUE,
recursive = TRUE),
to = newdir.temp, overwrite = TRUE)
next('already ran ABC with base values, copied Forecast2030 into placeholder')
}
# if (catch == 'upper'){
#   next('not yet implemented upper catch stream, skipping')
# }
df<-data.frame()
rootdir.temp <- paste0(rootdir,"/cr",r )
## specific catch values here
catch_projections <- read.csv(paste0(rootdir.temp,"/cproj_",r,".csv"))
Flimitfraction <- catch_projections$PSTAR_0.45[catch_projections$YEAR ==2030]
catch_proportions <- catch_projections[5,5:ncol(catch_projections)]
const.catch <- mean(rowSums(catch_projections[3:4,5:ncol(catch_projections)])) ## avg 2019/2020
fixed_catches <- catch_projections[1:4,5:ncol(catch_projections)]
replist0 <- SS_output(paste0(rootdir.temp,"/base2015")) ## get values specific to this region
lastrun <- paste0(rootdir.temp,"/forecasts/forecast2030")
newdir.temp <- paste0(rootdir,"/cr",r,"_",catch,"_",state)
dir.create(newdir.temp) ## make special folder and copy files
file.copy(list.files(lastrun,
full.names = TRUE,
recursive = TRUE),
to = newdir.temp, overwrite = TRUE)
setwd(newdir.temp)
## Update Starter to read from CTL
if(state != 'base'){
strt <- SS_readstarter(file = "starter.ss")
strt$init_values_src <- 0
strt$last_estimation_phase <- 10 ## could go as high as 20
SS_writestarter(strt, file = "starter.ss", overwrite = TRUE)
}
## update CTL file with state of nature low/base/high (all fixed, reading from par)
mctl <- readLines(list.files(newdir.temp)[grep('_control', list.files(newdir.temp))])
LOI <- grep("NatM_p_1_Fem_GP_1",mctl)[1] ## get line(s) containing data after natm, ignoring comment
NewLine <- strsplit(mctl[LOI],"   ") ## split
## TABLE G stitching ----
rootdir <- "C:/Users/Maia Kapur/Dropbox/UW/assessments/china_2019_update/chinarock-update-2019"
if(catch == 'ABC' & state == 'base'){
rootdir.temp <- paste0(rootdir,"/cr",r )
lastrun <- paste0(rootdir.temp,"/forecasts/forecast2030")
newdir.temp <- paste0(rootdir,"/cr",r,"_",catch,"_",state)
dir.create(newdir.temp) ## make special folder and copy files
file.copy(list.files(lastrun,
full.names = TRUE,
recursive = TRUE),
to = newdir.temp, overwrite = TRUE)
next('already ran ABC with base values, copied Forecast2030 into placeholder')
}
# if (catch == 'upper'){
#   next('not yet implemented upper catch stream, skipping')
# }
df<-data.frame()
rootdir.temp <- paste0(rootdir,"/cr",r )
## specific catch values here
catch_projections <- read.csv(paste0(rootdir.temp,"/cproj_",r,".csv"))
Flimitfraction <- catch_projections$PSTAR_0.45[catch_projections$YEAR ==2030]
catch_proportions <- catch_projections[5,5:ncol(catch_projections)]
const.catch <- mean(rowSums(catch_projections[3:4,5:ncol(catch_projections)])) ## avg 2019/2020
fixed_catches <- catch_projections[1:4,5:ncol(catch_projections)]
replist0 <- SS_output(paste0(rootdir.temp,"/base2015")) ## get values specific to this region
lastrun <- paste0(rootdir.temp,"/forecasts/forecast2030")
newdir.temp <- paste0(rootdir,"/cr",r,"_",catch,"_",state)
dir.create(newdir.temp) ## make special folder and copy files
file.copy(list.files(lastrun,
full.names = TRUE,
recursive = TRUE),
to = newdir.temp, overwrite = TRUE)
setwd(newdir.temp)
## Update Starter to read from CTL
if(state != 'base'){
strt <- SS_readstarter(file = "starter.ss")
strt$init_values_src <- 0
strt$last_estimation_phase <- 10 ## could go as high as 20
SS_writestarter(strt, file = "starter.ss", overwrite = TRUE)
}
## update CTL file with state of nature low/base/high (all fixed, reading from par)
mctl <- readLines(list.files(newdir.temp)[grep('_control', list.files(newdir.temp))])
LOI <- grep("NatM_p_1_Fem_GP_1",mctl)[1] ## get line(s) containing data after natm, ignoring comment
NewLine <- strsplit(mctl[LOI],"   ") ## split elements
NewLine[[1]][3]
NewLine[[1]][3] <- ifelse(state == 'low', 0.05, ifelse(state == 'high', 0.08, 0.07))
paste0(NewLine[[1]], collapse = " ")
## fixed catch for next decision table is average of 2019/2020 input
## I am going to hard code this -- not manual but not function
#
forecast_start <- 2021; forecast_end <- 2031; t = 11
## base M is -2.94, low is -2.99, high is -2.41
for(r in c('North','Central','South')){ ## loop regions
for(catch in c('constant','ABC','upper')){ ## loop catch scen
for(state in c('low','base','high')){
if(catch == 'ABC' & state == 'base'){
rootdir.temp <- paste0(rootdir,"/cr",r )
lastrun <- paste0(rootdir.temp,"/forecasts/forecast2030")
newdir.temp <- paste0(rootdir,"/cr",r,"_",catch,"_",state)
dir.create(newdir.temp) ## make special folder and copy files
file.copy(list.files(lastrun,
full.names = TRUE,
recursive = TRUE),
to = newdir.temp, overwrite = TRUE)
next('already ran ABC with base values, copied Forecast2030 into placeholder')
}
# if (catch == 'upper'){
#   next('not yet implemented upper catch stream, skipping')
# }
df<-data.frame()
rootdir.temp <- paste0(rootdir,"/cr",r )
## specific catch values here
catch_projections <- read.csv(paste0(rootdir.temp,"/cproj_",r,".csv"))
Flimitfraction <- catch_projections$PSTAR_0.45[catch_projections$YEAR ==2030]
catch_proportions <- catch_projections[5,5:ncol(catch_projections)]
const.catch <- mean(rowSums(catch_projections[3:4,5:ncol(catch_projections)])) ## avg 2019/2020
fixed_catches <- catch_projections[1:4,5:ncol(catch_projections)]
replist0 <- SS_output(paste0(rootdir.temp,"/base2015")) ## get values specific to this region
lastrun <- paste0(rootdir.temp,"/forecasts/forecast2030")
newdir.temp <- paste0(rootdir,"/cr",r,"_",catch,"_",state)
dir.create(newdir.temp) ## make special folder and copy files
file.copy(list.files(lastrun,
full.names = TRUE,
recursive = TRUE),
to = newdir.temp, overwrite = TRUE)
setwd(newdir.temp)
## Update Starter to read from CTL
if(state != 'base'){
strt <- SS_readstarter(file = "starter.ss")
strt$init_values_src <- 0
strt$last_estimation_phase <- 10 ## could go as high as 20
SS_writestarter(strt, file = "starter.ss", overwrite = TRUE)
}
## update CTL file with state of nature low/base/high (all fixed, reading from par)
mctl <- readLines(list.files(newdir.temp)[grep('_control', list.files(newdir.temp))])
LOI <- grep("NatM_p_1_Fem_GP_1",mctl)[1] ## get line(s) containing data after natm, ignoring comment
NewLine <- strsplit(mctl[LOI],"   ") ## split elements
NewLine[[1]][3] <- ifelse(state == 'low', 0.05, ifelse(state == 'high', 0.08, 0.07))
mctl[LOI][1] = paste0(NewLine[[1]], collapse = " ")
writeLines(text=mctl, con= paste(list.files(newdir.temp)[grep('_control', list.files(newdir.temp))])) ## save it
## read in and replace forecast file with appropriate catches ----
## REPLACE WITH ORIGINAL FORECAST FILE SINCE SS_READFORECAST CAN'T DEAL WITH OPTION #2 YET
file.copy(from = paste0(rootdir.temp,"/base2015/forecast.ss"), to = paste0(newdir.temp,"/forecast.ss"), overwrite = TRUE)
fore <- SS_readforecast(file = './forecast.ss',
Nareas = replist0$nareas,
Nfleets = replist0$nfishfleets,
version = paste(replist0$SS_versionNumeric),
readAll = TRUE)
fore$Nforecastyrs <- 2031-replist0$endyr
fore$FirstYear_for_caps_and_allocations <- forecast_start+(t-1)
fore$Ncatch <- replist0$nfishfleets*(t+forecast_start-replist0$endyr-2)
fore$InputBasis <- 2 ## discards
## Now Add Catch data/projections thru the year before forecast_start.
## This acts similarly to SS_ForeCatch except it reads directly from your inputs.
inityr <- max(fore$ForeCatch$Year)
for(k in 1:(forecast_start-1-inityr)){
term <- nrow(fore$ForeCatch) ## intital final row
for(i in 1:replist0$nfishfleets){
fore$ForeCatch[term+i,'Year'] <- inityr+k
fore$ForeCatch[term+i,'Seas'] <- 1
fore$ForeCatch[term+i,'Fleet'] <- i
fore$ForeCatch[term+i,'Catch_or_F'] <- fixed_catches[k,i]
} ## end nfleets
} ## end yrs to 2020
## Fix forecast file to end year selectivity
fore$Bmark_years[1:6] <- 0
fore$Fcast_years[1:4] <- 0
## Fix trawl relative F to reflect proportional catch amounts by fleet in forecast.
fore$fleet_relative_F <- 2 ## will cause original r4ss write_forecast to fail
fore$vals_fleet_relative_f <- paste(paste0(catch_proportions, collapse = " "))
fore$basis_for_fcast_catch_tuning <- 2 ## dead biomass
##  Input correct buffer fraction for this year
fore$Flimitfraction <- Flimitfraction
mod1 <- SS_output(paste0(rootdir.temp,"/forecasts/forecast2021"), covar = FALSE) ## just load once
predOFLs_startForecast <-  mod1$derived_quants[grep(paste0("ForeCatch_",(forecast_start+(t-2)),collapse = "|"), mod1$derived_quants$Label),"Value"]
if(catch == 'ABC'){
tempForeCatch <- SS_ForeCatch(mod1,
yrs = 2021:(2021+(t-2)),
average = FALSE,
total = predOFLs_startForecast) ## will update based on changing buffer
fore$ForeCatch[(nrow(fore$ForeCatch)+1):(nrow(fore$ForeCatch)+nrow(tempForeCatch)),] <- tempForeCatch[,1:4]
write.csv(tempForeCatch, file = "./tempForeCatch.csv",row.names = FALSE) ## save final year ABC catch
} else if(catch == 'constant'){
tempForeCatch <- SS_ForeCatch(mod1,
yrs = 2021:(2021+(t-2)),
average = FALSE,
total = const.catch)
fore$ForeCatch[(nrow(fore$ForeCatch)+1):(nrow(fore$ForeCatch)+nrow(tempForeCatch)),] <- tempForeCatch[,1:4]
write.csv(tempForeCatch, file = "./tempForeCatch.csv",row.names = FALSE) ## save final year ABC catch
} else if (catch == 'upper'){
upperStream <- 1.5*mod1$derived_quants[grep("ForeCatch_2021", mod1$derived_quants$Label),"Value"]
tempForeCatch <- SS_ForeCatch(mod1,
yrs = 2021:(2021+(t-2)),
average = FALSE,
total = upperStream)
fore$ForeCatch[(nrow(fore$ForeCatch)+1):(nrow(fore$ForeCatch)+nrow(tempForeCatch)),] <- tempForeCatch[,1:4]
write.csv(tempForeCatch, file = "./tempForeCatch.csv",row.names = FALSE) ## save final year ABC catch
# next('not yet implemented upper catch stream, skipping')
}
## save file
SS_writeforecastMK(fore, file = './forecast.ss', overwrite = TRUE)
## execute this model
setwd(newdir.temp); system('ss3 -nohess') ## works
## extract values of interest ----
modX <- SS_output(newdir.temp, covar = FALSE)
YOI <- (replist0$endyr+1):(forecast_end-1); lYOI <- length(YOI)
## this will read the output of the first model and save the OFLs
## which will get used to compute subsequent mods
## https://github.com/melmonk/StockAssessment_template/blob/master/8a_Tables.Rmd
df[1:lYOI,"Year"] <- YOI
df[1:lYOI,"PredOFL"] <-  modX$derived_quants[grep(paste0("OFLCatch_",YOI,collapse = "|"), modX$derived_quants$Label),"Value"]
df[1:lYOI,"ForeCatch_ABC"] <- modX$derived_quants[grep(paste0("ForeCatch_",YOI,collapse = "|"), modX$derived_quants$Label),"Value"]
df[1:lYOI,"SpawnBio"] <- modX$derived_quants[grep(paste0("SSB_",YOI,collapse = "|"), modX$derived_quants$Label),"Value"]
df[1:lYOI,"Depletion"] <- paste0(round(modX$derived_quants[grep(paste0("Bratio_",YOI,collapse = "|"), modX$derived_quants$Label),"Value"],3)*100,"%")
df$PredOFL[df$Year < forecast_start] <- df$ForeCatch_ABC[df$Year < forecast_start]<- NA
df[,2:4] <- round(df[,2:4],2)
df %>% mutate('REG' = r, 'State of Nature' = state, 'Catch' = catch) %>%
write.csv(.,file = paste0(newdir.temp,"/summary_table_f.csv"),row.names = FALSE)
} ## end states of nature
} ## end catch scenarios
} ## end regions
require(dplyr)
require(readr)
require(purrr)
require(kaputils)
require(r4ss)
devtools::source_url("https://raw.githubusercontent.com/mkapur/kaputils/master/R/SS_readforecastMK.R") ## use dev version
devtools::source_url("https://raw.githubusercontent.com/r4ss/r4ss/development/R/SS_ForeCatch.R") ## use dev version
devtools::source_url("https://raw.githubusercontent.com/mkapur/kaputils/master/R/SS_writeforecastMK.R") ## use dev version
# devtools::source_url("https://raw.githubusercontent.com/mkapur/kaputils/master/R/SS_executivesummaryMK.R")
## Execute automated forecasts
# for(r in c('North','Central','South')){
#   rootdir.t
## fixed catch for next decision table is average of 2019/2020 input
## I am going to hard code this -- not manual but not function
#
forecast_start <- 2021; forecast_end <- 2031; t = 11
## base M is -2.94, low is -2.99, high is -2.41
for(r in c('North','Central','South')){ ## loop regions
for(catch in c('constant','ABC','upper')){ ## loop catch scen
for(state in c('low','base','high')){
if(catch == 'ABC' & state == 'base'){
rootdir.temp <- paste0(rootdir,"/cr",r )
lastrun <- paste0(rootdir.temp,"/forecasts/forecast2030")
newdir.temp <- paste0(rootdir,"/cr",r,"_",catch,"_",state)
dir.create(newdir.temp) ## make special folder and copy files
file.copy(list.files(lastrun,
full.names = TRUE,
recursive = TRUE),
to = newdir.temp, overwrite = TRUE)
next('already ran ABC with base values, copied Forecast2030 into placeholder')
}
# if (catch == 'upper'){
#   next('not yet implemented upper catch stream, skipping')
# }
df<-data.frame()
rootdir.temp <- paste0(rootdir,"/cr",r )
## specific catch values here
catch_projections <- read.csv(paste0(rootdir.temp,"/cproj_",r,".csv"))
Flimitfraction <- catch_projections$PSTAR_0.45[catch_projections$YEAR ==2030]
catch_proportions <- catch_projections[5,5:ncol(catch_projections)]
const.catch <- mean(rowSums(catch_projections[3:4,5:ncol(catch_projections)])) ## avg 2019/2020
fixed_catches <- catch_projections[1:4,5:ncol(catch_projections)]
replist0 <- SS_output(paste0(rootdir.temp,"/base2015")) ## get values specific to this region
lastrun <- paste0(rootdir.temp,"/forecasts/forecast2030")
newdir.temp <- paste0(rootdir,"/cr",r,"_",catch,"_",state)
dir.create(newdir.temp) ## make special folder and copy files
file.copy(list.files(lastrun,
full.names = TRUE,
recursive = TRUE),
to = newdir.temp, overwrite = TRUE)
setwd(newdir.temp)
## Update Starter to read from CTL
if(state != 'base'){
strt <- SS_readstarter(file = "starter.ss")
strt$init_values_src <- 0
strt$last_estimation_phase <- 10 ## could go as high as 20
SS_writestarter(strt, file = "starter.ss", overwrite = TRUE)
}
## update CTL file with state of nature low/base/high (all fixed, reading from par)
mctl <- readLines(list.files(newdir.temp)[grep('_control', list.files(newdir.temp))])
LOI <- grep("NatM_p_1_Fem_GP_1",mctl)[1] ## get line(s) containing data after natm, ignoring comment
NewLine <- strsplit(mctl[LOI],"   ") ## split elements
NewLine[[1]][3] <- ifelse(state == 'low', 0.05, ifelse(state == 'high', 0.08, 0.07))
mctl[LOI][1] = paste0(NewLine[[1]], collapse = " ")
writeLines(text=mctl, con= paste(list.files(newdir.temp)[grep('_control', list.files(newdir.temp))])) ## save it
## read in and replace forecast file with appropriate catches ----
## REPLACE WITH ORIGINAL FORECAST FILE SINCE SS_READFORECAST CAN'T DEAL WITH OPTION #2 YET
file.copy(from = paste0(rootdir.temp,"/base2015/forecast.ss"), to = paste0(newdir.temp,"/forecast.ss"), overwrite = TRUE)
fore <- SS_readforecast(file = './forecast.ss',
Nareas = replist0$nareas,
Nfleets = replist0$nfishfleets,
version = paste(replist0$SS_versionNumeric),
readAll = TRUE)
fore$Nforecastyrs <- 2031-replist0$endyr
fore$FirstYear_for_caps_and_allocations <- forecast_start+(t-1)
fore$Ncatch <- replist0$nfishfleets*(t+forecast_start-replist0$endyr-2)
fore$InputBasis <- 2 ## discards
## Now Add Catch data/projections thru the year before forecast_start.
## This acts similarly to SS_ForeCatch except it reads directly from your inputs.
inityr <- max(fore$ForeCatch$Year)
for(k in 1:(forecast_start-1-inityr)){
term <- nrow(fore$ForeCatch) ## intital final row
for(i in 1:replist0$nfishfleets){
fore$ForeCatch[term+i,'Year'] <- inityr+k
fore$ForeCatch[term+i,'Seas'] <- 1
fore$ForeCatch[term+i,'Fleet'] <- i
fore$ForeCatch[term+i,'Catch_or_F'] <- fixed_catches[k,i]
} ## end nfleets
} ## end yrs to 2020
## Fix forecast file to end year selectivity
fore$Bmark_years[1:6] <- 0
fore$Fcast_years[1:4] <- 0
## Fix trawl relative F to reflect proportional catch amounts by fleet in forecast.
fore$fleet_relative_F <- 2 ## will cause original r4ss write_forecast to fail
fore$vals_fleet_relative_f <- paste(paste0(catch_proportions, collapse = " "))
fore$basis_for_fcast_catch_tuning <- 2 ## dead biomass
##  Input correct buffer fraction for this year
fore$Flimitfraction <- Flimitfraction
mod1 <- SS_output(paste0(rootdir.temp,"/forecasts/forecast2021"), covar = FALSE) ## just load once
predOFLs_startForecast <-  mod1$derived_quants[grep(paste0("ForeCatch_",(forecast_start+(t-2)),collapse = "|"), mod1$derived_quants$Label),"Value"]
if(catch == 'ABC'){
tempForeCatch <- SS_ForeCatch(mod1,
yrs = 2021:(2021+(t-2)),
average = FALSE,
total = predOFLs_startForecast) ## will update based on changing buffer
fore$ForeCatch[(nrow(fore$ForeCatch)+1):(nrow(fore$ForeCatch)+nrow(tempForeCatch)),] <- tempForeCatch[,1:4]
write.csv(tempForeCatch, file = "./tempForeCatch.csv",row.names = FALSE) ## save final year ABC catch
} else if(catch == 'constant'){
tempForeCatch <- SS_ForeCatch(mod1,
yrs = 2021:(2021+(t-2)),
average = FALSE,
total = const.catch)
fore$ForeCatch[(nrow(fore$ForeCatch)+1):(nrow(fore$ForeCatch)+nrow(tempForeCatch)),] <- tempForeCatch[,1:4]
write.csv(tempForeCatch, file = "./tempForeCatch.csv",row.names = FALSE) ## save final year ABC catch
} else if (catch == 'upper'){
upperStream <- 1.5*mod1$derived_quants[grep("ForeCatch_2021", mod1$derived_quants$Label),"Value"]
tempForeCatch <- SS_ForeCatch(mod1,
yrs = 2021:(2021+(t-2)),
average = FALSE,
total = upperStream)
fore$ForeCatch[(nrow(fore$ForeCatch)+1):(nrow(fore$ForeCatch)+nrow(tempForeCatch)),] <- tempForeCatch[,1:4]
write.csv(tempForeCatch, file = "./tempForeCatch.csv",row.names = FALSE) ## save final year ABC catch
# next('not yet implemented upper catch stream, skipping')
}
## save file
SS_writeforecastMK(fore, file = './forecast.ss', overwrite = TRUE)
## execute this model
setwd(newdir.temp); system('ss3 -nohess') ## works
## extract values of interest ----
modX <- SS_output(newdir.temp, covar = FALSE)
YOI <- (replist0$endyr+1):(forecast_end-1); lYOI <- length(YOI)
## this will read the output of the first model and save the OFLs
## which will get used to compute subsequent mods
## https://github.com/melmonk/StockAssessment_template/blob/master/8a_Tables.Rmd
df[1:lYOI,"Year"] <- YOI
df[1:lYOI,"PredOFL"] <-  modX$derived_quants[grep(paste0("OFLCatch_",YOI,collapse = "|"), modX$derived_quants$Label),"Value"]
df[1:lYOI,"ForeCatch_ABC"] <- modX$derived_quants[grep(paste0("ForeCatch_",YOI,collapse = "|"), modX$derived_quants$Label),"Value"]
df[1:lYOI,"SpawnBio"] <- modX$derived_quants[grep(paste0("SSB_",YOI,collapse = "|"), modX$derived_quants$Label),"Value"]
df[1:lYOI,"Depletion"] <- paste0(round(modX$derived_quants[grep(paste0("Bratio_",YOI,collapse = "|"), modX$derived_quants$Label),"Value"],3)*100,"%")
df$PredOFL[df$Year < forecast_start] <- df$ForeCatch_ABC[df$Year < forecast_start]<- NA
df[,2:4] <- round(df[,2:4],2)
df %>% mutate('REG' = r, 'State of Nature' = state, 'Catch' = catch) %>%
write.csv(.,file = paste0(newdir.temp,"/summary_table_f.csv"),row.names = FALSE)
} ## end states of nature
} ## end catch scenarios
} ## end regions
require(stringr)
rootdir <- "C:/Users/Maia Kapur/Dropbox/UW/assessments/china_2019_update/chinarock-update-2019"
regdirs <- list.dirs(rootdir,recursive = FALSE)[grep('cr',list.dirs(rootdir,recursive = FALSE))]
#
regnames <- basename(dirname(list.files(regdirs, recursive = FALSE, full.names = TRUE)[grep('*summary_table_f.csv',list.files(regdirs,recursive = FALSE,full.names = TRUE))]))
df <- list.files(regdirs, recursive = FALSE, full.names = TRUE)[grep('*summary_table_f.csv',list.files(regdirs,recursive = FALSE,full.names = TRUE))] %>%
lapply(.,read.csv)%>% bind_rows()
write.csv(df,paste0(rootdir,"./",Sys.Date(),"table_f.csv"), row.names = TRUE)
View(df)
regdirs <- list.dirs(rootdir,recursive = FALSE)[grep('cr',list.dirs(rootdir,recursive = FALSE))]
regnames <- basename(regdirs)
df <- list.files(regdirs, recursive = TRUE, full.names = TRUE)[grep('decision_table_base.csv',list.files(regdirs,recursive = TRUE,full.names = TRUE))] %>%
map_df(~ read_csv(.,
col_types = cols(.default = "c")),
.id="index") %>%
mutate( REG = gsub( "cr", "", regnames[as.numeric(index)] ))
write.csv(df,paste0(rootdir,"./",Sys.Date(),"table_g.csv"), row.names = FALSE)
list.dirs(rootdir,recursive = FALSE)[grep('cr',list.dirs(rootdir,recursive = FALSE))]
## TABLE G stitching ----
rootdir <- "C:/Users/Maia Kapur/Dropbox/UW/assessments/china_2019_update/chinarock-update-2019/tgfiles"
regdirs <- list.dirs(rootdir,recursive = FALSE)[grep('cr',list.dirs(rootdir,recursive = FALSE))]
regnames <- basename(regdirs)
df <- list.files(regdirs, recursive = TRUE, full.names = TRUE)[grep('decision_table_base.csv',list.files(regdirs,recursive = TRUE,full.names = TRUE))] %>%
map_df(~ read_csv(.,
col_types = cols(.default = "c")),
.id="index") %>%
mutate( REG = gsub( "cr", "", regnames[as.numeric(index)] ))
df
regdirs
list.files(regdirs, recursive = TRUE, full.names = TRUE)[grep('decision_table_base.csv',list.files(regdirs,recursive = TRUE,full.names = TRUE))]
list.files(regdirs, recursive = TRUE, full.names = TRUE)[grep('decision_table_base.csv',list.files(regdirs,recursive = TRUE,full.names = TRUE))] %>%
map_df(~ read_csv(.,
col_types = cols(.default = "c")),
.id="index") %>%
mutate( REG = gsub( "cr", "", regnames[as.numeric(index)] ))
df <- list.files(regdirs, recursive = TRUE, full.names = TRUE)[grep('decision_table_base.csv',list.files(regdirs,recursive = TRUE,full.names = TRUE))] %>%
map_df(~ read_csv(.,
col_types = cols(.default = "c")),
.id="index") %>%
mutate( REG = gsub( "cr", "", regnames[as.numeric(index)] ))
write.csv(df,paste0(rootdir,"./",Sys.Date(),"table_g.csv"), row.names = FALSE)
